2025-10-28 14:24:39,188:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 14:24:39,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 14:24:39,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 14:24:39,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 14:48:09,093:INFO:PyCaret RegressionExperiment
2025-10-28 14:48:09,093:INFO:Logging name: reg-default-name
2025-10-28 14:48:09,093:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-28 14:48:09,096:INFO:version 3.3.2
2025-10-28 14:48:09,096:INFO:Initializing setup()
2025-10-28 14:48:09,096:INFO:self.USI: cc1b
2025-10-28 14:48:09,096:INFO:self._variable_keys: {'exp_id', 'data', 'exp_name_log', 'X_train', 'fold_shuffle_param', 'fold_groups_param', 'idx', 'pipeline', 'logging_param', 'y', 'gpu_param', 'memory', 'n_jobs_param', 'log_plots_param', 'fold_generator', 'gpu_n_jobs_param', 'y_train', 'target_param', 'transform_target_param', 'X', '_available_plots', 'y_test', '_ml_usecase', 'html_param', 'X_test', 'seed', 'USI'}
2025-10-28 14:48:09,096:INFO:Checking environment
2025-10-28 14:48:09,096:INFO:python_version: 3.11.0
2025-10-28 14:48:09,096:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-28 14:48:09,096:INFO:machine: AMD64
2025-10-28 14:48:09,096:INFO:platform: Windows-10-10.0.26200-SP0
2025-10-28 14:48:09,097:INFO:Memory: svmem(total=16405516288, available=4609392640, percent=71.9, used=11796123648, free=4609392640)
2025-10-28 14:48:09,097:INFO:Physical Core: 8
2025-10-28 14:48:09,097:INFO:Logical Core: 16
2025-10-28 14:48:09,097:INFO:Checking libraries
2025-10-28 14:48:09,097:INFO:System:
2025-10-28 14:48:09,097:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-28 14:48:09,097:INFO:executable: c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\python.exe
2025-10-28 14:48:09,097:INFO:   machine: Windows-10-10.0.26200-SP0
2025-10-28 14:48:09,097:INFO:PyCaret required dependencies:
2025-10-28 14:48:09,112:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  "this condition will fail. "

2025-10-28 14:48:09,180:INFO:                 pip: 25.3
2025-10-28 14:48:09,180:INFO:          setuptools: 80.9.0
2025-10-28 14:48:09,180:INFO:             pycaret: 3.3.2
2025-10-28 14:48:09,180:INFO:             IPython: 9.6.0
2025-10-28 14:48:09,180:INFO:          ipywidgets: 8.1.7
2025-10-28 14:48:09,180:INFO:                tqdm: 4.67.1
2025-10-28 14:48:09,180:INFO:               numpy: 1.26.4
2025-10-28 14:48:09,180:INFO:              pandas: 2.1.4
2025-10-28 14:48:09,180:INFO:              jinja2: 3.1.6
2025-10-28 14:48:09,180:INFO:               scipy: 1.11.4
2025-10-28 14:48:09,180:INFO:              joblib: 1.3.2
2025-10-28 14:48:09,183:INFO:             sklearn: 1.4.2
2025-10-28 14:48:09,183:INFO:                pyod: 2.0.5
2025-10-28 14:48:09,183:INFO:            imblearn: 0.14.0
2025-10-28 14:48:09,183:INFO:   category_encoders: 2.7.0
2025-10-28 14:48:09,183:INFO:            lightgbm: 4.6.0
2025-10-28 14:48:09,183:INFO:               numba: 0.62.1
2025-10-28 14:48:09,183:INFO:            requests: 2.32.5
2025-10-28 14:48:09,183:INFO:          matplotlib: 3.7.5
2025-10-28 14:48:09,183:INFO:          scikitplot: 0.3.7
2025-10-28 14:48:09,183:INFO:         yellowbrick: 1.5
2025-10-28 14:48:09,184:INFO:              plotly: 6.3.1
2025-10-28 14:48:09,184:INFO:    plotly-resampler: Not installed
2025-10-28 14:48:09,184:INFO:             kaleido: 1.1.0
2025-10-28 14:48:09,184:INFO:           schemdraw: 0.15
2025-10-28 14:48:09,184:INFO:         statsmodels: 0.14.5
2025-10-28 14:48:09,184:INFO:              sktime: 0.26.0
2025-10-28 14:48:09,184:INFO:               tbats: 1.1.3
2025-10-28 14:48:09,184:INFO:            pmdarima: 2.0.4
2025-10-28 14:48:09,184:INFO:              psutil: 7.1.2
2025-10-28 14:48:09,184:INFO:          markupsafe: 3.0.3
2025-10-28 14:48:09,184:INFO:             pickle5: Not installed
2025-10-28 14:48:09,184:INFO:         cloudpickle: 3.1.1
2025-10-28 14:48:09,184:INFO:         deprecation: 2.1.0
2025-10-28 14:48:09,184:INFO:              xxhash: 3.6.0
2025-10-28 14:48:09,184:INFO:           wurlitzer: Not installed
2025-10-28 14:48:09,184:INFO:PyCaret optional dependencies:
2025-10-28 14:48:09,206:INFO:                shap: Not installed
2025-10-28 14:48:09,206:INFO:           interpret: Not installed
2025-10-28 14:48:09,206:INFO:                umap: Not installed
2025-10-28 14:48:09,206:INFO:     ydata_profiling: Not installed
2025-10-28 14:48:09,206:INFO:  explainerdashboard: Not installed
2025-10-28 14:48:09,206:INFO:             autoviz: Not installed
2025-10-28 14:48:09,206:INFO:           fairlearn: Not installed
2025-10-28 14:48:09,206:INFO:          deepchecks: Not installed
2025-10-28 14:48:09,206:INFO:             xgboost: Not installed
2025-10-28 14:48:09,206:INFO:            catboost: Not installed
2025-10-28 14:48:09,206:INFO:              kmodes: Not installed
2025-10-28 14:48:09,206:INFO:             mlxtend: Not installed
2025-10-28 14:48:09,206:INFO:       statsforecast: Not installed
2025-10-28 14:48:09,206:INFO:        tune_sklearn: Not installed
2025-10-28 14:48:09,206:INFO:                 ray: Not installed
2025-10-28 14:48:09,206:INFO:            hyperopt: Not installed
2025-10-28 14:48:09,206:INFO:              optuna: Not installed
2025-10-28 14:48:09,206:INFO:               skopt: Not installed
2025-10-28 14:48:09,206:INFO:              mlflow: Not installed
2025-10-28 14:48:09,206:INFO:              gradio: Not installed
2025-10-28 14:48:09,206:INFO:             fastapi: Not installed
2025-10-28 14:48:09,206:INFO:             uvicorn: Not installed
2025-10-28 14:48:09,206:INFO:              m2cgen: Not installed
2025-10-28 14:48:09,206:INFO:           evidently: Not installed
2025-10-28 14:48:09,206:INFO:               fugue: Not installed
2025-10-28 14:48:09,206:INFO:           streamlit: Not installed
2025-10-28 14:48:09,206:INFO:             prophet: Not installed
2025-10-28 14:48:09,206:INFO:None
2025-10-28 14:48:09,206:INFO:Set up data.
2025-10-28 14:48:09,237:INFO:Set up folding strategy.
2025-10-28 14:48:09,237:INFO:Set up train/test split.
2025-10-28 14:48:09,297:INFO:Set up index.
2025-10-28 14:48:09,297:INFO:Assigning column types.
2025-10-28 14:48:09,313:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 14:48:09,313:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,319:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,323:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,397:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,451:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:09,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:09,451:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,458:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,462:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,530:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,569:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,569:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:09,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:09,569:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-28 14:48:09,584:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,590:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,657:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,703:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,703:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:09,703:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:09,703:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,703:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,769:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,830:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,830:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:09,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:09,830:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-28 14:48:09,844:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,910:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,956:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 14:48:09,957:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:09,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:09,965:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 14:48:10,022:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 14:48:10,075:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 14:48:10,075:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:10,075:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:10,075:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-28 14:48:10,149:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 14:48:10,188:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 14:48:10,188:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:10,188:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:10,254:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 14:48:10,306:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 14:48:10,308:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:10,308:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:10,308:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 14:48:10,378:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 14:48:10,419:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:10,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:10,490:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 14:48:10,522:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:10,522:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:10,522:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-28 14:48:10,647:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:10,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:10,755:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:10,755:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:10,772:INFO:Preparing preprocessing pipeline...
2025-10-28 14:48:10,772:INFO:Set up simple imputation.
2025-10-28 14:48:10,776:INFO:Set up encoding of ordinal features.
2025-10-28 14:48:10,791:INFO:Set up encoding of categorical features.
2025-10-28 14:48:11,388:INFO:Finished creating preprocessing pipeline.
2025-10-28 14:48:11,437:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LESANM~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Id', 'MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'B...
                                                                    'Condition2',
                                                                    'BldgType',
                                                                    'HouseStyle',
                                                                    'RoofStyle',
                                                                    'RoofMatl',
                                                                    'Exterior1st',
                                                                    'Exterior2nd',
                                                                    'MasVnrType',
                                                                    'ExterQual',
                                                                    'ExterCond',
                                                                    'Foundation',
                                                                    'BsmtQual',
                                                                    'BsmtCond',
                                                                    'BsmtExposure',
                                                                    'BsmtFinType1',
                                                                    'BsmtFinType2',
                                                                    'Heating',
                                                                    'HeatingQC',
                                                                    'Electrical',
                                                                    'KitchenQual',
                                                                    'Functional',
                                                                    'FireplaceQu',
                                                                    'GarageType', ...],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2025-10-28 14:48:11,437:INFO:Creating final display dataframe.
2025-10-28 14:48:12,956:INFO:Setup _display_container:                     Description             Value
0                    Session id              9999
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape        (1460, 81)
4        Transformed data shape       (1460, 281)
5   Transformed train set shape       (1021, 281)
6    Transformed test set shape        (439, 281)
7              Numeric features                37
8          Categorical features                43
9      Rows with missing values            100.0%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation            median
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              cc1b
2025-10-28 14:48:13,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:13,086:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:13,198:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:13,198:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 14:48:13,199:INFO:setup() successfully completed in 4.11s...............
2025-10-28 14:48:21,005:INFO:Initializing compare_models()
2025-10-28 14:48:21,005:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-10-28 14:48:21,005:INFO:Checking exceptions
2025-10-28 14:48:21,013:INFO:Preparing display monitor
2025-10-28 14:48:21,043:INFO:Initializing Linear Regression
2025-10-28 14:48:21,043:INFO:Total runtime is 0.0 minutes
2025-10-28 14:48:21,047:INFO:SubProcess create_model() called ==================================
2025-10-28 14:48:21,047:INFO:Initializing create_model()
2025-10-28 14:48:21,048:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000216678C5510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:48:21,048:INFO:Checking exceptions
2025-10-28 14:48:21,048:INFO:Importing libraries
2025-10-28 14:48:21,048:INFO:Copying training dataset
2025-10-28 14:48:21,066:INFO:Defining folds
2025-10-28 14:48:21,066:INFO:Declaring metric variables
2025-10-28 14:48:21,071:INFO:Importing untrained model
2025-10-28 14:48:21,071:INFO:Linear Regression Imported successfully
2025-10-28 14:48:21,076:INFO:Starting cross validation
2025-10-28 14:48:21,099:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:48:28,250:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-10-28 14:48:28,251:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-10-28 14:48:28,251:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-10-28 14:48:28,253:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-10-28 14:48:28,253:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-10-28 14:48:28,253:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-10-28 14:48:28,253:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-10-28 14:48:28,255:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-10-28 14:48:28,255:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-10-28 14:48:29,652:INFO:Calculating mean and std
2025-10-28 14:48:29,655:INFO:Creating metrics dataframe
2025-10-28 14:48:29,659:INFO:Uploading results into container
2025-10-28 14:48:29,659:INFO:Uploading model into container now
2025-10-28 14:48:29,661:INFO:_master_model_container: 1
2025-10-28 14:48:29,661:INFO:_display_container: 2
2025-10-28 14:48:29,661:INFO:LinearRegression(n_jobs=-1)
2025-10-28 14:48:29,661:INFO:create_model() successfully completed......................................
2025-10-28 14:48:29,802:INFO:SubProcess create_model() end ==================================
2025-10-28 14:48:29,804:INFO:Creating metrics dataframe
2025-10-28 14:48:29,808:INFO:Initializing Lasso Regression
2025-10-28 14:48:29,808:INFO:Total runtime is 0.1460837244987488 minutes
2025-10-28 14:48:29,810:INFO:SubProcess create_model() called ==================================
2025-10-28 14:48:29,810:INFO:Initializing create_model()
2025-10-28 14:48:29,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000216678C5510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:48:29,810:INFO:Checking exceptions
2025-10-28 14:48:29,810:INFO:Importing libraries
2025-10-28 14:48:29,810:INFO:Copying training dataset
2025-10-28 14:48:29,822:INFO:Defining folds
2025-10-28 14:48:29,822:INFO:Declaring metric variables
2025-10-28 14:48:29,834:INFO:Importing untrained model
2025-10-28 14:48:29,836:INFO:Lasso Regression Imported successfully
2025-10-28 14:48:29,846:INFO:Starting cross validation
2025-10-28 14:48:29,854:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:48:31,173:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.540e+09, tolerance: 5.805e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:31,173:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.791e+08, tolerance: 5.611e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:31,209:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.691e+11, tolerance: 5.894e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:33,748:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-10-28 14:48:33,754:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-10-28 14:48:33,754:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-10-28 14:48:33,754:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-10-28 14:48:33,757:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-10-28 14:48:33,825:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-10-28 14:48:34,764:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.674e+11, tolerance: 5.710e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:34,795:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.739e+10, tolerance: 5.875e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:34,797:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.102e+10, tolerance: 5.818e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:34,799:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.386e+09, tolerance: 5.456e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:34,807:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.578e+11, tolerance: 5.871e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:34,874:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.990e+08, tolerance: 5.699e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:35,060:INFO:Calculating mean and std
2025-10-28 14:48:35,062:INFO:Creating metrics dataframe
2025-10-28 14:48:35,064:INFO:Uploading results into container
2025-10-28 14:48:35,064:INFO:Uploading model into container now
2025-10-28 14:48:35,064:INFO:_master_model_container: 2
2025-10-28 14:48:35,065:INFO:_display_container: 2
2025-10-28 14:48:35,065:INFO:Lasso(random_state=9999)
2025-10-28 14:48:35,065:INFO:create_model() successfully completed......................................
2025-10-28 14:48:35,197:INFO:SubProcess create_model() end ==================================
2025-10-28 14:48:35,198:INFO:Creating metrics dataframe
2025-10-28 14:48:35,201:INFO:Initializing Ridge Regression
2025-10-28 14:48:35,201:INFO:Total runtime is 0.23597424030303957 minutes
2025-10-28 14:48:35,207:INFO:SubProcess create_model() called ==================================
2025-10-28 14:48:35,207:INFO:Initializing create_model()
2025-10-28 14:48:35,207:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000216678C5510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:48:35,207:INFO:Checking exceptions
2025-10-28 14:48:35,207:INFO:Importing libraries
2025-10-28 14:48:35,207:INFO:Copying training dataset
2025-10-28 14:48:35,215:INFO:Defining folds
2025-10-28 14:48:35,215:INFO:Declaring metric variables
2025-10-28 14:48:35,223:INFO:Importing untrained model
2025-10-28 14:48:35,229:INFO:Ridge Regression Imported successfully
2025-10-28 14:48:35,234:INFO:Starting cross validation
2025-10-28 14:48:35,247:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:48:36,586:INFO:Calculating mean and std
2025-10-28 14:48:36,588:INFO:Creating metrics dataframe
2025-10-28 14:48:36,590:INFO:Uploading results into container
2025-10-28 14:48:36,591:INFO:Uploading model into container now
2025-10-28 14:48:36,592:INFO:_master_model_container: 3
2025-10-28 14:48:36,592:INFO:_display_container: 2
2025-10-28 14:48:36,592:INFO:Ridge(random_state=9999)
2025-10-28 14:48:36,592:INFO:create_model() successfully completed......................................
2025-10-28 14:48:36,721:INFO:SubProcess create_model() end ==================================
2025-10-28 14:48:36,721:INFO:Creating metrics dataframe
2025-10-28 14:48:36,728:INFO:Initializing Elastic Net
2025-10-28 14:48:36,728:INFO:Total runtime is 0.26142541964848837 minutes
2025-10-28 14:48:36,731:INFO:SubProcess create_model() called ==================================
2025-10-28 14:48:36,731:INFO:Initializing create_model()
2025-10-28 14:48:36,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000216678C5510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:48:36,731:INFO:Checking exceptions
2025-10-28 14:48:36,731:INFO:Importing libraries
2025-10-28 14:48:36,731:INFO:Copying training dataset
2025-10-28 14:48:36,743:INFO:Defining folds
2025-10-28 14:48:36,745:INFO:Declaring metric variables
2025-10-28 14:48:36,748:INFO:Importing untrained model
2025-10-28 14:48:36,751:INFO:Elastic Net Imported successfully
2025-10-28 14:48:36,758:INFO:Starting cross validation
2025-10-28 14:48:36,765:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:48:38,552:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.724e+11, tolerance: 5.875e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:38,557:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.599e+11, tolerance: 5.818e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:38,579:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.734e+11, tolerance: 5.871e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:38,589:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.727e+11, tolerance: 5.699e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:38,589:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.115e+11, tolerance: 5.456e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:38,623:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.496e+11, tolerance: 5.710e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:38,648:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.350e+11, tolerance: 5.611e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:38,662:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.448e+11, tolerance: 5.805e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:38,681:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.604e+11, tolerance: 5.751e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:38,728:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.757e+11, tolerance: 5.894e+08
  model = cd_fast.enet_coordinate_descent(

2025-10-28 14:48:38,877:INFO:Calculating mean and std
2025-10-28 14:48:38,879:INFO:Creating metrics dataframe
2025-10-28 14:48:38,881:INFO:Uploading results into container
2025-10-28 14:48:38,882:INFO:Uploading model into container now
2025-10-28 14:48:38,882:INFO:_master_model_container: 4
2025-10-28 14:48:38,882:INFO:_display_container: 2
2025-10-28 14:48:38,882:INFO:ElasticNet(random_state=9999)
2025-10-28 14:48:38,882:INFO:create_model() successfully completed......................................
2025-10-28 14:48:39,005:INFO:SubProcess create_model() end ==================================
2025-10-28 14:48:39,005:INFO:Creating metrics dataframe
2025-10-28 14:48:39,011:INFO:Initializing Least Angle Regression
2025-10-28 14:48:39,011:INFO:Total runtime is 0.2994766195615133 minutes
2025-10-28 14:48:39,014:INFO:SubProcess create_model() called ==================================
2025-10-28 14:48:39,014:INFO:Initializing create_model()
2025-10-28 14:48:39,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000216678C5510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:48:39,015:INFO:Checking exceptions
2025-10-28 14:48:39,015:INFO:Importing libraries
2025-10-28 14:48:39,015:INFO:Copying training dataset
2025-10-28 14:48:39,028:INFO:Defining folds
2025-10-28 14:48:39,028:INFO:Declaring metric variables
2025-10-28 14:48:39,033:INFO:Importing untrained model
2025-10-28 14:48:39,034:INFO:Least Angle Regression Imported successfully
2025-10-28 14:48:39,039:INFO:Starting cross validation
2025-10-28 14:48:39,049:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:48:40,237:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=4.146e+02, with an active set of 58 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,238:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=5.782e+02, with an active set of 55 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,243:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=2.668e+02, with an active set of 72 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,243:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=2.861e+02, with an active set of 74 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,248:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=2.078e+02, with an active set of 84 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,282:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=3.480e+02, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,284:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=3.674e+02, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,314:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=4.103e+02, with an active set of 79 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,318:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=3.528e+02, with an active set of 90 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,324:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=6.345e+03, with an active set of 188 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,335:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=6.691e+02, with an active set of 207 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,338:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=5.462e+06, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,342:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=8.147e+03, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,343:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 301 iterations, i.e. alpha=5.395e+06, with an active set of 235 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,346:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=8.149e+03, with an active set of 192 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,350:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=7.786e+03, with an active set of 211 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,352:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=1.613e+03, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,355:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 316 iterations, i.e. alpha=5.467e+06, with an active set of 248 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,368:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=3.702e+03, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,368:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 335 iterations, i.e. alpha=6.381e+06, with an active set of 264 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,370:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.076e+03, with an active set of 223 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,370:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.846e+03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,371:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=2.076e+03, with an active set of 224 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,371:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.209e+03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,372:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=9.475e+06, with an active set of 266 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,373:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=8.467e+02, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,376:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=8.203e+06, with an active set of 269 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,376:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=5.409e+06, with an active set of 269 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,376:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=4.408e+06, with an active set of 269 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,376:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=6.567e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,376:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=6.122e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,376:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=6.416e+02, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,376:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=4.304e+06, with an active set of 270 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,378:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=4.590e+02, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,380:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=4.431e+02, with an active set of 64 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,380:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=4.310e+06, with an active set of 273 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,381:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=3.308e+06, with an active set of 273 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,381:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=2.461e+06, with an active set of 273 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,382:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=4.377e+02, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,383:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=1.994e+06, with an active set of 275 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,385:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=7.883e+05, with an active set of 275 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,385:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=3.072e+02, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2025-10-28 14:48:40,386:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=2.619e+02, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,387:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.845e+05, with an active set of 276 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,388:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.586e+04, with an active set of 276 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,388:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=2.470e+02, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,388:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=4.849e+03, with an active set of 276 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,389:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=2.374e+02, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,389:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=2.416e+03, with an active set of 181 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,389:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.353e+02, with an active set of 88 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,391:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=2.364e+02, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,392:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=2.181e+02, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,393:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=2.148e+02, with an active set of 92 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,393:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=2.205e+02, with an active set of 88 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,393:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.061e+02, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,394:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=2.005e+02, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,395:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=1.975e+02, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,395:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.951e+02, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,397:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.922e+02, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,397:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=1.912e+02, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,398:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=1.844e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,400:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=5.343e+04, with an active set of 210 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,401:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.777e+02, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,403:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=1.762e+02, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,403:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=1.263e+07, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,403:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=3.499e+05, with an active set of 106 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,407:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=2.915e+05, with an active set of 109 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,407:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.183e+05, with an active set of 110 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,409:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 139 iterations, i.e. alpha=3.674e+12, with an active set of 111 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,411:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 365 iterations, i.e. alpha=1.397e+14, with an active set of 277 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,411:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=1.333e+11, with an active set of 112 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,411:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=1.120e+11, with an active set of 113 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,413:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=1.049e+11, with an active set of 114 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,420:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 380 iterations, i.e. alpha=1.587e+06, with an active set of 275 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,420:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 380 iterations, i.e. alpha=1.657e+05, with an active set of 275 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,422:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 381 iterations, i.e. alpha=9.448e+04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,422:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 381 iterations, i.e. alpha=2.362e+04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,423:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 363 iterations, i.e. alpha=1.119e+05, with an active set of 273 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,423:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 363 iterations, i.e. alpha=9.406e+04, with an active set of 273 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,424:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 363 iterations, i.e. alpha=6.306e+04, with an active set of 273 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,427:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 366 iterations, i.e. alpha=1.137e+05, with an active set of 275 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,427:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 366 iterations, i.e. alpha=4.334e+04, with an active set of 275 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,440:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 299 iterations, i.e. alpha=2.018e+05, with an active set of 244 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,440:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 376 iterations, i.e. alpha=5.845e+08, with an active set of 277 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,442:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 376 iterations, i.e. alpha=4.818e+08, with an active set of 277 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,442:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 363 iterations, i.e. alpha=7.132e+06, with an active set of 274 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,442:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 316 iterations, i.e. alpha=3.557e+05, with an active set of 257 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,442:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 363 iterations, i.e. alpha=3.268e+06, with an active set of 274 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,451:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 328 iterations, i.e. alpha=3.768e+05, with an active set of 266 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,455:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 336 iterations, i.e. alpha=2.475e+06, with an active set of 272 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,455:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 337 iterations, i.e. alpha=7.456e+05, with an active set of 273 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,457:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=1.525e+07, with an active set of 275 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,457:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=7.060e+05, with an active set of 275 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,458:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=3.546e+05, with an active set of 276 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:40,688:INFO:Calculating mean and std
2025-10-28 14:48:40,690:INFO:Creating metrics dataframe
2025-10-28 14:48:40,692:INFO:Uploading results into container
2025-10-28 14:48:40,692:INFO:Uploading model into container now
2025-10-28 14:48:40,692:INFO:_master_model_container: 5
2025-10-28 14:48:40,692:INFO:_display_container: 2
2025-10-28 14:48:40,694:INFO:Lars(random_state=9999)
2025-10-28 14:48:40,694:INFO:create_model() successfully completed......................................
2025-10-28 14:48:40,818:INFO:SubProcess create_model() end ==================================
2025-10-28 14:48:40,820:INFO:Creating metrics dataframe
2025-10-28 14:48:40,824:INFO:Initializing Lasso Least Angle Regression
2025-10-28 14:48:40,824:INFO:Total runtime is 0.32969964742660524 minutes
2025-10-28 14:48:40,829:INFO:SubProcess create_model() called ==================================
2025-10-28 14:48:40,829:INFO:Initializing create_model()
2025-10-28 14:48:40,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000216678C5510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:48:40,829:INFO:Checking exceptions
2025-10-28 14:48:40,830:INFO:Importing libraries
2025-10-28 14:48:40,831:INFO:Copying training dataset
2025-10-28 14:48:40,845:INFO:Defining folds
2025-10-28 14:48:40,845:INFO:Declaring metric variables
2025-10-28 14:48:40,851:INFO:Importing untrained model
2025-10-28 14:48:40,855:INFO:Lasso Least Angle Regression Imported successfully
2025-10-28 14:48:40,859:INFO:Starting cross validation
2025-10-28 14:48:40,871:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:48:41,907:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=5.902e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:41,911:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=4.482e+02, with an active set of 59 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:41,927:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 44 iterations, alpha=1.748e+03, previous alpha=1.380e+03, with an active set of 39 regressors.
  warnings.warn(

2025-10-28 14:48:41,938:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.313e+02, with an active set of 78 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:41,941:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=2.085e+02, with an active set of 81 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:41,946:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=4.504e+02, with an active set of 57 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:41,965:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 168 iterations, alpha=6.078e+02, previous alpha=1.079e+02, with an active set of 115 regressors.
  warnings.warn(

2025-10-28 14:48:41,967:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=3.324e+04, previous alpha=3.131e+04, with an active set of 22 regressors.
  warnings.warn(

2025-10-28 14:48:41,970:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=1.902e+02, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:41,986:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=5.086e+02, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:42,001:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=2.645e+02, with an active set of 73 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:42,006:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 172 iterations, alpha=7.783e+01, previous alpha=7.783e+01, with an active set of 127 regressors.
  warnings.warn(

2025-10-28 14:48:42,008:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 196 iterations, alpha=5.039e+01, previous alpha=5.009e+01, with an active set of 153 regressors.
  warnings.warn(

2025-10-28 14:48:42,015:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 135 iterations, alpha=1.484e+02, previous alpha=1.484e+02, with an active set of 96 regressors.
  warnings.warn(

2025-10-28 14:48:42,015:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 102 iterations, alpha=3.315e+02, previous alpha=3.306e+02, with an active set of 65 regressors.
  warnings.warn(

2025-10-28 14:48:42,017:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=1.365e+03, previous alpha=4.591e+02, with an active set of 61 regressors.
  warnings.warn(

2025-10-28 14:48:42,045:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=6.300e+02, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:42,046:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=5.152e+02, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:42,053:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=4.267e+02, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:42,061:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=2.531e+02, with an active set of 77 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:42,069:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=2.255e+02, with an active set of 83 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:42,076:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.310e+02, with an active set of 96 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:42,078:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=1.061e+02, with an active set of 108 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:42,078:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 164 iterations, i.e. alpha=8.798e+01, with an active set of 124 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:42,097:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 201 iterations, i.e. alpha=5.315e+01, with an active set of 143 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-10-28 14:48:42,109:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 221 iterations, alpha=3.771e+01, previous alpha=3.770e+01, with an active set of 172 regressors.
  warnings.warn(

2025-10-28 14:48:42,117:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 228 iterations, alpha=4.350e+01, previous alpha=4.350e+01, with an active set of 159 regressors.
  warnings.warn(

2025-10-28 14:48:42,269:INFO:Calculating mean and std
2025-10-28 14:48:42,269:INFO:Creating metrics dataframe
2025-10-28 14:48:42,269:INFO:Uploading results into container
2025-10-28 14:48:42,269:INFO:Uploading model into container now
2025-10-28 14:48:42,269:INFO:_master_model_container: 6
2025-10-28 14:48:42,269:INFO:_display_container: 2
2025-10-28 14:48:42,269:INFO:LassoLars(random_state=9999)
2025-10-28 14:48:42,269:INFO:create_model() successfully completed......................................
2025-10-28 14:48:42,387:INFO:SubProcess create_model() end ==================================
2025-10-28 14:48:42,387:INFO:Creating metrics dataframe
2025-10-28 14:48:42,403:INFO:Initializing Orthogonal Matching Pursuit
2025-10-28 14:48:42,403:INFO:Total runtime is 0.35600717067718507 minutes
2025-10-28 14:48:42,403:INFO:SubProcess create_model() called ==================================
2025-10-28 14:48:42,403:INFO:Initializing create_model()
2025-10-28 14:48:42,403:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000216678C5510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:48:42,403:INFO:Checking exceptions
2025-10-28 14:48:42,403:INFO:Importing libraries
2025-10-28 14:48:42,403:INFO:Copying training dataset
2025-10-28 14:48:42,419:INFO:Defining folds
2025-10-28 14:48:42,419:INFO:Declaring metric variables
2025-10-28 14:48:42,425:INFO:Importing untrained model
2025-10-28 14:48:42,430:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-28 14:48:42,438:INFO:Starting cross validation
2025-10-28 14:48:42,446:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:48:43,729:INFO:Calculating mean and std
2025-10-28 14:48:43,731:INFO:Creating metrics dataframe
2025-10-28 14:48:43,734:INFO:Uploading results into container
2025-10-28 14:48:43,734:INFO:Uploading model into container now
2025-10-28 14:48:43,735:INFO:_master_model_container: 7
2025-10-28 14:48:43,735:INFO:_display_container: 2
2025-10-28 14:48:43,735:INFO:OrthogonalMatchingPursuit()
2025-10-28 14:48:43,735:INFO:create_model() successfully completed......................................
2025-10-28 14:48:43,858:INFO:SubProcess create_model() end ==================================
2025-10-28 14:48:43,858:INFO:Creating metrics dataframe
2025-10-28 14:48:43,864:INFO:Initializing Bayesian Ridge
2025-10-28 14:48:43,864:INFO:Total runtime is 0.3803654948870341 minutes
2025-10-28 14:48:43,869:INFO:SubProcess create_model() called ==================================
2025-10-28 14:48:43,869:INFO:Initializing create_model()
2025-10-28 14:48:43,869:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000216678C5510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:48:43,869:INFO:Checking exceptions
2025-10-28 14:48:43,869:INFO:Importing libraries
2025-10-28 14:48:43,869:INFO:Copying training dataset
2025-10-28 14:48:43,869:INFO:Defining folds
2025-10-28 14:48:43,869:INFO:Declaring metric variables
2025-10-28 14:48:43,887:INFO:Importing untrained model
2025-10-28 14:48:43,894:INFO:Bayesian Ridge Imported successfully
2025-10-28 14:48:43,896:INFO:Starting cross validation
2025-10-28 14:48:43,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:48:45,357:INFO:Calculating mean and std
2025-10-28 14:48:45,357:INFO:Creating metrics dataframe
2025-10-28 14:48:45,360:INFO:Uploading results into container
2025-10-28 14:48:45,360:INFO:Uploading model into container now
2025-10-28 14:48:45,360:INFO:_master_model_container: 8
2025-10-28 14:48:45,360:INFO:_display_container: 2
2025-10-28 14:48:45,360:INFO:BayesianRidge()
2025-10-28 14:48:45,360:INFO:create_model() successfully completed......................................
2025-10-28 14:48:45,489:INFO:SubProcess create_model() end ==================================
2025-10-28 14:48:45,489:INFO:Creating metrics dataframe
2025-10-28 14:48:45,490:INFO:Initializing Passive Aggressive Regressor
2025-10-28 14:48:45,490:INFO:Total runtime is 0.4074650446573893 minutes
2025-10-28 14:48:45,490:INFO:SubProcess create_model() called ==================================
2025-10-28 14:48:45,490:INFO:Initializing create_model()
2025-10-28 14:48:45,490:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000216678C5510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:48:45,490:INFO:Checking exceptions
2025-10-28 14:48:45,490:INFO:Importing libraries
2025-10-28 14:48:45,490:INFO:Copying training dataset
2025-10-28 14:48:45,507:INFO:Defining folds
2025-10-28 14:48:45,507:INFO:Declaring metric variables
2025-10-28 14:48:45,515:INFO:Importing untrained model
2025-10-28 14:48:45,521:INFO:Passive Aggressive Regressor Imported successfully
2025-10-28 14:48:45,526:INFO:Starting cross validation
2025-10-28 14:48:45,534:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:48:46,871:INFO:Calculating mean and std
2025-10-28 14:48:46,873:INFO:Creating metrics dataframe
2025-10-28 14:48:46,875:INFO:Uploading results into container
2025-10-28 14:48:46,876:INFO:Uploading model into container now
2025-10-28 14:48:46,876:INFO:_master_model_container: 9
2025-10-28 14:48:46,876:INFO:_display_container: 2
2025-10-28 14:48:46,876:INFO:PassiveAggressiveRegressor(random_state=9999)
2025-10-28 14:48:46,876:INFO:create_model() successfully completed......................................
2025-10-28 14:48:47,000:INFO:SubProcess create_model() end ==================================
2025-10-28 14:48:47,000:INFO:Creating metrics dataframe
2025-10-28 14:48:47,012:INFO:Initializing Huber Regressor
2025-10-28 14:48:47,012:INFO:Total runtime is 0.4328261574109395 minutes
2025-10-28 14:48:47,013:INFO:SubProcess create_model() called ==================================
2025-10-28 14:48:47,013:INFO:Initializing create_model()
2025-10-28 14:48:47,013:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000216678C5510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:48:47,013:INFO:Checking exceptions
2025-10-28 14:48:47,016:INFO:Importing libraries
2025-10-28 14:48:47,016:INFO:Copying training dataset
2025-10-28 14:48:47,024:INFO:Defining folds
2025-10-28 14:48:47,024:INFO:Declaring metric variables
2025-10-28 14:48:47,034:INFO:Importing untrained model
2025-10-28 14:48:47,044:INFO:Huber Regressor Imported successfully
2025-10-28 14:48:47,053:INFO:Starting cross validation
2025-10-28 14:48:47,061:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:48:48,689:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 14:48:48,697:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 14:48:48,876:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 14:48:48,890:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 14:48:48,924:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 14:48:48,927:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 14:48:48,930:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 14:48:48,947:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 14:48:48,948:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 14:48:48,969:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 14:48:49,144:INFO:Calculating mean and std
2025-10-28 14:48:49,144:INFO:Creating metrics dataframe
2025-10-28 14:48:49,146:INFO:Uploading results into container
2025-10-28 14:48:49,146:INFO:Uploading model into container now
2025-10-28 14:48:49,146:INFO:_master_model_container: 10
2025-10-28 14:48:49,146:INFO:_display_container: 2
2025-10-28 14:48:49,146:INFO:HuberRegressor()
2025-10-28 14:48:49,146:INFO:create_model() successfully completed......................................
2025-10-28 14:48:49,273:INFO:SubProcess create_model() end ==================================
2025-10-28 14:48:49,273:INFO:Creating metrics dataframe
2025-10-28 14:48:49,280:INFO:Initializing K Neighbors Regressor
2025-10-28 14:48:49,280:INFO:Total runtime is 0.4706229448318481 minutes
2025-10-28 14:48:49,280:INFO:SubProcess create_model() called ==================================
2025-10-28 14:48:49,280:INFO:Initializing create_model()
2025-10-28 14:48:49,280:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000216678C5510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:48:49,280:INFO:Checking exceptions
2025-10-28 14:48:49,280:INFO:Importing libraries
2025-10-28 14:48:49,280:INFO:Copying training dataset
2025-10-28 14:48:49,301:INFO:Defining folds
2025-10-28 14:48:49,301:INFO:Declaring metric variables
2025-10-28 14:48:49,305:INFO:Importing untrained model
2025-10-28 14:48:49,305:INFO:K Neighbors Regressor Imported successfully
2025-10-28 14:48:49,316:INFO:Starting cross validation
2025-10-28 14:48:49,322:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:48:50,626:INFO:Calculating mean and std
2025-10-28 14:48:50,628:INFO:Creating metrics dataframe
2025-10-28 14:48:50,631:INFO:Uploading results into container
2025-10-28 14:48:50,631:INFO:Uploading model into container now
2025-10-28 14:48:50,631:INFO:_master_model_container: 11
2025-10-28 14:48:50,631:INFO:_display_container: 2
2025-10-28 14:48:50,631:INFO:KNeighborsRegressor(n_jobs=-1)
2025-10-28 14:48:50,631:INFO:create_model() successfully completed......................................
2025-10-28 14:48:50,754:INFO:SubProcess create_model() end ==================================
2025-10-28 14:48:50,754:INFO:Creating metrics dataframe
2025-10-28 14:48:50,763:INFO:Initializing Decision Tree Regressor
2025-10-28 14:48:50,763:INFO:Total runtime is 0.49533345699310294 minutes
2025-10-28 14:48:50,765:INFO:SubProcess create_model() called ==================================
2025-10-28 14:48:50,767:INFO:Initializing create_model()
2025-10-28 14:48:50,767:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000216678C5510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:48:50,767:INFO:Checking exceptions
2025-10-28 14:48:50,767:INFO:Importing libraries
2025-10-28 14:48:50,767:INFO:Copying training dataset
2025-10-28 14:48:50,767:INFO:Defining folds
2025-10-28 14:48:50,779:INFO:Declaring metric variables
2025-10-28 14:48:50,782:INFO:Importing untrained model
2025-10-28 14:48:50,786:INFO:Decision Tree Regressor Imported successfully
2025-10-28 14:48:50,792:INFO:Starting cross validation
2025-10-28 14:48:50,801:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:48:52,138:INFO:Calculating mean and std
2025-10-28 14:48:52,140:INFO:Creating metrics dataframe
2025-10-28 14:48:52,140:INFO:Uploading results into container
2025-10-28 14:48:52,140:INFO:Uploading model into container now
2025-10-28 14:48:52,140:INFO:_master_model_container: 12
2025-10-28 14:48:52,140:INFO:_display_container: 2
2025-10-28 14:48:52,140:INFO:DecisionTreeRegressor(random_state=9999)
2025-10-28 14:48:52,140:INFO:create_model() successfully completed......................................
2025-10-28 14:48:52,267:INFO:SubProcess create_model() end ==================================
2025-10-28 14:48:52,267:INFO:Creating metrics dataframe
2025-10-28 14:48:52,267:INFO:Initializing Random Forest Regressor
2025-10-28 14:48:52,267:INFO:Total runtime is 0.5204117774963378 minutes
2025-10-28 14:48:52,267:INFO:SubProcess create_model() called ==================================
2025-10-28 14:48:52,267:INFO:Initializing create_model()
2025-10-28 14:48:52,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000216678C5510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:48:52,267:INFO:Checking exceptions
2025-10-28 14:48:52,279:INFO:Importing libraries
2025-10-28 14:48:52,279:INFO:Copying training dataset
2025-10-28 14:48:52,284:INFO:Defining folds
2025-10-28 14:48:52,284:INFO:Declaring metric variables
2025-10-28 14:48:52,297:INFO:Importing untrained model
2025-10-28 14:48:52,303:INFO:Random Forest Regressor Imported successfully
2025-10-28 14:48:52,309:INFO:Starting cross validation
2025-10-28 14:48:52,315:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:48:55,748:INFO:Calculating mean and std
2025-10-28 14:48:55,748:INFO:Creating metrics dataframe
2025-10-28 14:48:55,748:INFO:Uploading results into container
2025-10-28 14:48:55,748:INFO:Uploading model into container now
2025-10-28 14:48:55,748:INFO:_master_model_container: 13
2025-10-28 14:48:55,753:INFO:_display_container: 2
2025-10-28 14:48:55,754:INFO:RandomForestRegressor(n_jobs=-1, random_state=9999)
2025-10-28 14:48:55,754:INFO:create_model() successfully completed......................................
2025-10-28 14:48:55,887:INFO:SubProcess create_model() end ==================================
2025-10-28 14:48:55,888:INFO:Creating metrics dataframe
2025-10-28 14:48:55,896:INFO:Initializing Extra Trees Regressor
2025-10-28 14:48:55,896:INFO:Total runtime is 0.580893858273824 minutes
2025-10-28 14:48:55,899:INFO:SubProcess create_model() called ==================================
2025-10-28 14:48:55,899:INFO:Initializing create_model()
2025-10-28 14:48:55,899:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000216678C5510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:48:55,899:INFO:Checking exceptions
2025-10-28 14:48:55,899:INFO:Importing libraries
2025-10-28 14:48:55,899:INFO:Copying training dataset
2025-10-28 14:48:55,913:INFO:Defining folds
2025-10-28 14:48:55,913:INFO:Declaring metric variables
2025-10-28 14:48:55,917:INFO:Importing untrained model
2025-10-28 14:48:55,922:INFO:Extra Trees Regressor Imported successfully
2025-10-28 14:48:55,926:INFO:Starting cross validation
2025-10-28 14:48:55,939:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:48:59,455:INFO:Calculating mean and std
2025-10-28 14:48:59,457:INFO:Creating metrics dataframe
2025-10-28 14:48:59,459:INFO:Uploading results into container
2025-10-28 14:48:59,459:INFO:Uploading model into container now
2025-10-28 14:48:59,460:INFO:_master_model_container: 14
2025-10-28 14:48:59,460:INFO:_display_container: 2
2025-10-28 14:48:59,461:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=9999)
2025-10-28 14:48:59,461:INFO:create_model() successfully completed......................................
2025-10-28 14:48:59,580:INFO:SubProcess create_model() end ==================================
2025-10-28 14:48:59,580:INFO:Creating metrics dataframe
2025-10-28 14:48:59,580:INFO:Initializing AdaBoost Regressor
2025-10-28 14:48:59,580:INFO:Total runtime is 0.6422895391782124 minutes
2025-10-28 14:48:59,594:INFO:SubProcess create_model() called ==================================
2025-10-28 14:48:59,596:INFO:Initializing create_model()
2025-10-28 14:48:59,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000216678C5510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:48:59,596:INFO:Checking exceptions
2025-10-28 14:48:59,596:INFO:Importing libraries
2025-10-28 14:48:59,596:INFO:Copying training dataset
2025-10-28 14:48:59,597:INFO:Defining folds
2025-10-28 14:48:59,597:INFO:Declaring metric variables
2025-10-28 14:48:59,613:INFO:Importing untrained model
2025-10-28 14:48:59,617:INFO:AdaBoost Regressor Imported successfully
2025-10-28 14:48:59,617:INFO:Starting cross validation
2025-10-28 14:48:59,632:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:49:01,942:INFO:Calculating mean and std
2025-10-28 14:49:01,942:INFO:Creating metrics dataframe
2025-10-28 14:49:01,946:INFO:Uploading results into container
2025-10-28 14:49:01,946:INFO:Uploading model into container now
2025-10-28 14:49:01,946:INFO:_master_model_container: 15
2025-10-28 14:49:01,946:INFO:_display_container: 2
2025-10-28 14:49:01,946:INFO:AdaBoostRegressor(random_state=9999)
2025-10-28 14:49:01,946:INFO:create_model() successfully completed......................................
2025-10-28 14:49:02,064:INFO:SubProcess create_model() end ==================================
2025-10-28 14:49:02,064:INFO:Creating metrics dataframe
2025-10-28 14:49:02,081:INFO:Initializing Gradient Boosting Regressor
2025-10-28 14:49:02,081:INFO:Total runtime is 0.683967125415802 minutes
2025-10-28 14:49:02,081:INFO:SubProcess create_model() called ==================================
2025-10-28 14:49:02,081:INFO:Initializing create_model()
2025-10-28 14:49:02,081:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000216678C5510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:49:02,081:INFO:Checking exceptions
2025-10-28 14:49:02,081:INFO:Importing libraries
2025-10-28 14:49:02,081:INFO:Copying training dataset
2025-10-28 14:49:02,103:INFO:Defining folds
2025-10-28 14:49:02,104:INFO:Declaring metric variables
2025-10-28 14:49:02,105:INFO:Importing untrained model
2025-10-28 14:49:02,108:INFO:Gradient Boosting Regressor Imported successfully
2025-10-28 14:49:02,116:INFO:Starting cross validation
2025-10-28 14:49:02,122:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:49:04,309:INFO:Calculating mean and std
2025-10-28 14:49:04,310:INFO:Creating metrics dataframe
2025-10-28 14:49:04,311:INFO:Uploading results into container
2025-10-28 14:49:04,311:INFO:Uploading model into container now
2025-10-28 14:49:04,311:INFO:_master_model_container: 16
2025-10-28 14:49:04,311:INFO:_display_container: 2
2025-10-28 14:49:04,311:INFO:GradientBoostingRegressor(random_state=9999)
2025-10-28 14:49:04,311:INFO:create_model() successfully completed......................................
2025-10-28 14:49:04,437:INFO:SubProcess create_model() end ==================================
2025-10-28 14:49:04,437:INFO:Creating metrics dataframe
2025-10-28 14:49:04,451:INFO:Initializing Light Gradient Boosting Machine
2025-10-28 14:49:04,451:INFO:Total runtime is 0.7234770854314168 minutes
2025-10-28 14:49:04,454:INFO:SubProcess create_model() called ==================================
2025-10-28 14:49:04,454:INFO:Initializing create_model()
2025-10-28 14:49:04,454:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000216678C5510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:49:04,454:INFO:Checking exceptions
2025-10-28 14:49:04,454:INFO:Importing libraries
2025-10-28 14:49:04,454:INFO:Copying training dataset
2025-10-28 14:49:04,456:INFO:Defining folds
2025-10-28 14:49:04,456:INFO:Declaring metric variables
2025-10-28 14:49:04,470:INFO:Importing untrained model
2025-10-28 14:49:04,473:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-28 14:49:04,478:INFO:Starting cross validation
2025-10-28 14:49:04,487:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:49:07,213:INFO:Calculating mean and std
2025-10-28 14:49:07,214:INFO:Creating metrics dataframe
2025-10-28 14:49:07,216:INFO:Uploading results into container
2025-10-28 14:49:07,218:INFO:Uploading model into container now
2025-10-28 14:49:07,218:INFO:_master_model_container: 17
2025-10-28 14:49:07,219:INFO:_display_container: 2
2025-10-28 14:49:07,219:INFO:LGBMRegressor(n_jobs=-1, random_state=9999)
2025-10-28 14:49:07,219:INFO:create_model() successfully completed......................................
2025-10-28 14:49:07,358:INFO:SubProcess create_model() end ==================================
2025-10-28 14:49:07,358:INFO:Creating metrics dataframe
2025-10-28 14:49:07,375:INFO:Initializing Dummy Regressor
2025-10-28 14:49:07,375:INFO:Total runtime is 0.7722005208333332 minutes
2025-10-28 14:49:07,379:INFO:SubProcess create_model() called ==================================
2025-10-28 14:49:07,379:INFO:Initializing create_model()
2025-10-28 14:49:07,379:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000216678C5510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:49:07,379:INFO:Checking exceptions
2025-10-28 14:49:07,379:INFO:Importing libraries
2025-10-28 14:49:07,379:INFO:Copying training dataset
2025-10-28 14:49:07,392:INFO:Defining folds
2025-10-28 14:49:07,392:INFO:Declaring metric variables
2025-10-28 14:49:07,392:INFO:Importing untrained model
2025-10-28 14:49:07,402:INFO:Dummy Regressor Imported successfully
2025-10-28 14:49:07,410:INFO:Starting cross validation
2025-10-28 14:49:07,416:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:49:08,724:INFO:Calculating mean and std
2025-10-28 14:49:08,725:INFO:Creating metrics dataframe
2025-10-28 14:49:08,727:INFO:Uploading results into container
2025-10-28 14:49:08,728:INFO:Uploading model into container now
2025-10-28 14:49:08,728:INFO:_master_model_container: 18
2025-10-28 14:49:08,728:INFO:_display_container: 2
2025-10-28 14:49:08,729:INFO:DummyRegressor()
2025-10-28 14:49:08,729:INFO:create_model() successfully completed......................................
2025-10-28 14:49:08,861:INFO:SubProcess create_model() end ==================================
2025-10-28 14:49:08,861:INFO:Creating metrics dataframe
2025-10-28 14:49:08,884:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-28 14:49:08,895:INFO:Initializing create_model()
2025-10-28 14:49:08,895:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=GradientBoostingRegressor(random_state=9999), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:49:08,895:INFO:Checking exceptions
2025-10-28 14:49:08,899:INFO:Importing libraries
2025-10-28 14:49:08,899:INFO:Copying training dataset
2025-10-28 14:49:08,915:INFO:Defining folds
2025-10-28 14:49:08,915:INFO:Declaring metric variables
2025-10-28 14:49:08,915:INFO:Importing untrained model
2025-10-28 14:49:08,916:INFO:Declaring custom model
2025-10-28 14:49:08,916:INFO:Gradient Boosting Regressor Imported successfully
2025-10-28 14:49:08,922:INFO:Cross validation set to False
2025-10-28 14:49:08,922:INFO:Fitting Model
2025-10-28 14:49:10,167:INFO:GradientBoostingRegressor(random_state=9999)
2025-10-28 14:49:10,167:INFO:create_model() successfully completed......................................
2025-10-28 14:49:10,319:INFO:_master_model_container: 18
2025-10-28 14:49:10,319:INFO:_display_container: 2
2025-10-28 14:49:10,320:INFO:GradientBoostingRegressor(random_state=9999)
2025-10-28 14:49:10,320:INFO:compare_models() successfully completed......................................
2025-10-28 14:49:35,958:INFO:Initializing create_model()
2025-10-28 14:49:35,958:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=gbr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:49:35,958:INFO:Checking exceptions
2025-10-28 14:49:35,974:INFO:Importing libraries
2025-10-28 14:49:35,978:INFO:Copying training dataset
2025-10-28 14:49:36,002:INFO:Defining folds
2025-10-28 14:49:36,002:INFO:Declaring metric variables
2025-10-28 14:49:36,007:INFO:Importing untrained model
2025-10-28 14:49:36,012:INFO:Gradient Boosting Regressor Imported successfully
2025-10-28 14:49:36,023:INFO:Starting cross validation
2025-10-28 14:49:36,034:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:49:38,376:INFO:Calculating mean and std
2025-10-28 14:49:38,376:INFO:Creating metrics dataframe
2025-10-28 14:49:38,381:INFO:Finalizing model
2025-10-28 14:49:39,663:INFO:Uploading results into container
2025-10-28 14:49:39,664:INFO:Uploading model into container now
2025-10-28 14:49:39,671:INFO:_master_model_container: 19
2025-10-28 14:49:39,671:INFO:_display_container: 3
2025-10-28 14:49:39,671:INFO:GradientBoostingRegressor(random_state=9999)
2025-10-28 14:49:39,671:INFO:create_model() successfully completed......................................
2025-10-28 14:49:45,231:INFO:Initializing tune_model()
2025-10-28 14:49:45,231:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=GradientBoostingRegressor(random_state=9999), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-28 14:49:45,232:INFO:Checking exceptions
2025-10-28 14:49:45,260:INFO:Copying training dataset
2025-10-28 14:49:45,274:INFO:Checking base model
2025-10-28 14:49:45,274:INFO:Base model : Gradient Boosting Regressor
2025-10-28 14:49:45,277:INFO:Declaring metric variables
2025-10-28 14:49:45,282:INFO:Defining Hyperparameters
2025-10-28 14:49:45,465:INFO:Tuning with n_jobs=-1
2025-10-28 14:49:45,465:INFO:Initializing RandomizedSearchCV
2025-10-28 14:50:03,351:INFO:best_params: {'actual_estimator__subsample': 0.2, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_samples_split': 4, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 4, 'actual_estimator__learning_rate': 0.1}
2025-10-28 14:50:03,353:INFO:Hyperparameter search completed
2025-10-28 14:50:03,353:INFO:SubProcess create_model() called ==================================
2025-10-28 14:50:03,354:INFO:Initializing create_model()
2025-10-28 14:50:03,355:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=GradientBoostingRegressor(random_state=9999), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002166771F090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.2, 'n_estimators': 130, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 4, 'learning_rate': 0.1})
2025-10-28 14:50:03,355:INFO:Checking exceptions
2025-10-28 14:50:03,355:INFO:Importing libraries
2025-10-28 14:50:03,356:INFO:Copying training dataset
2025-10-28 14:50:03,361:INFO:Defining folds
2025-10-28 14:50:03,361:INFO:Declaring metric variables
2025-10-28 14:50:03,373:INFO:Importing untrained model
2025-10-28 14:50:03,374:INFO:Declaring custom model
2025-10-28 14:50:03,378:INFO:Gradient Boosting Regressor Imported successfully
2025-10-28 14:50:03,383:INFO:Starting cross validation
2025-10-28 14:50:03,395:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:50:05,086:INFO:Calculating mean and std
2025-10-28 14:50:05,086:INFO:Creating metrics dataframe
2025-10-28 14:50:05,097:INFO:Finalizing model
2025-10-28 14:50:05,732:INFO:Uploading results into container
2025-10-28 14:50:05,735:INFO:Uploading model into container now
2025-10-28 14:50:05,735:INFO:_master_model_container: 20
2025-10-28 14:50:05,735:INFO:_display_container: 4
2025-10-28 14:50:05,735:INFO:GradientBoostingRegressor(max_depth=4, max_features='sqrt',
                          min_impurity_decrease=0.05, min_samples_leaf=5,
                          min_samples_split=4, n_estimators=130,
                          random_state=9999, subsample=0.2)
2025-10-28 14:50:05,735:INFO:create_model() successfully completed......................................
2025-10-28 14:50:05,884:INFO:SubProcess create_model() end ==================================
2025-10-28 14:50:05,884:INFO:choose_better activated
2025-10-28 14:50:05,887:INFO:SubProcess create_model() called ==================================
2025-10-28 14:50:05,888:INFO:Initializing create_model()
2025-10-28 14:50:05,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=GradientBoostingRegressor(random_state=9999), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:50:05,888:INFO:Checking exceptions
2025-10-28 14:50:05,891:INFO:Importing libraries
2025-10-28 14:50:05,891:INFO:Copying training dataset
2025-10-28 14:50:05,907:INFO:Defining folds
2025-10-28 14:50:05,909:INFO:Declaring metric variables
2025-10-28 14:50:05,909:INFO:Importing untrained model
2025-10-28 14:50:05,909:INFO:Declaring custom model
2025-10-28 14:50:05,910:INFO:Gradient Boosting Regressor Imported successfully
2025-10-28 14:50:05,911:INFO:Starting cross validation
2025-10-28 14:50:05,917:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 14:50:08,359:INFO:Calculating mean and std
2025-10-28 14:50:08,359:INFO:Creating metrics dataframe
2025-10-28 14:50:08,361:INFO:Finalizing model
2025-10-28 14:50:09,703:INFO:Uploading results into container
2025-10-28 14:50:09,705:INFO:Uploading model into container now
2025-10-28 14:50:09,705:INFO:_master_model_container: 21
2025-10-28 14:50:09,705:INFO:_display_container: 5
2025-10-28 14:50:09,705:INFO:GradientBoostingRegressor(random_state=9999)
2025-10-28 14:50:09,705:INFO:create_model() successfully completed......................................
2025-10-28 14:50:09,832:INFO:SubProcess create_model() end ==================================
2025-10-28 14:50:09,832:INFO:GradientBoostingRegressor(random_state=9999) result for R2 is 0.861
2025-10-28 14:50:09,832:INFO:GradientBoostingRegressor(max_depth=4, max_features='sqrt',
                          min_impurity_decrease=0.05, min_samples_leaf=5,
                          min_samples_split=4, n_estimators=130,
                          random_state=9999, subsample=0.2) result for R2 is 0.8531
2025-10-28 14:50:09,832:INFO:GradientBoostingRegressor(random_state=9999) is best model
2025-10-28 14:50:09,832:INFO:choose_better completed
2025-10-28 14:50:09,832:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-28 14:50:09,841:INFO:_master_model_container: 21
2025-10-28 14:50:09,841:INFO:_display_container: 4
2025-10-28 14:50:09,846:INFO:GradientBoostingRegressor(random_state=9999)
2025-10-28 14:50:09,846:INFO:tune_model() successfully completed......................................
2025-10-28 14:50:12,326:INFO:Initializing plot_model()
2025-10-28 14:50:12,326:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=GradientBoostingRegressor(random_state=9999), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-10-28 14:50:12,326:INFO:Checking exceptions
2025-10-28 14:50:12,339:INFO:Preloading libraries
2025-10-28 14:50:12,346:INFO:Copying training dataset
2025-10-28 14:50:12,346:INFO:Plot type: feature
2025-10-28 14:50:12,346:WARNING:No coef_ found. Trying feature_importances_
2025-10-28 14:50:12,693:INFO:Visual Rendered Successfully
2025-10-28 14:50:12,854:INFO:plot_model() successfully completed......................................
2025-10-28 14:50:16,126:INFO:Initializing predict_model()
2025-10-28 14:50:16,126:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=GradientBoostingRegressor(random_state=9999), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021669358220>)
2025-10-28 14:50:16,127:INFO:Checking exceptions
2025-10-28 14:50:16,127:INFO:Preloading libraries
2025-10-28 14:50:16,376:WARNING:c:\Users\lesanmartin\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-10-28 14:50:19,120:INFO:Initializing finalize_model()
2025-10-28 14:50:19,120:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=GradientBoostingRegressor(random_state=9999), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-28 14:50:19,120:INFO:Finalizing GradientBoostingRegressor(random_state=9999)
2025-10-28 14:50:19,131:INFO:Initializing create_model()
2025-10-28 14:50:19,131:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000216691A9990>, estimator=GradientBoostingRegressor(random_state=9999), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 14:50:19,131:INFO:Checking exceptions
2025-10-28 14:50:19,132:INFO:Importing libraries
2025-10-28 14:50:19,132:INFO:Copying training dataset
2025-10-28 14:50:19,134:INFO:Defining folds
2025-10-28 14:50:19,134:INFO:Declaring metric variables
2025-10-28 14:50:19,134:INFO:Importing untrained model
2025-10-28 14:50:19,134:INFO:Declaring custom model
2025-10-28 14:50:19,135:INFO:Gradient Boosting Regressor Imported successfully
2025-10-28 14:50:19,140:INFO:Cross validation set to False
2025-10-28 14:50:19,140:INFO:Fitting Model
2025-10-28 14:50:20,981:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Id', 'MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'BsmtFullBath', 'BsmtHalfBath',
                                             'FullBath', 'Hal...
                                                                    'Exterior1st',
                                                                    'Exterior2nd',
                                                                    'MasVnrType',
                                                                    'ExterQual',
                                                                    'ExterCond',
                                                                    'Foundation',
                                                                    'BsmtQual',
                                                                    'BsmtCond',
                                                                    'BsmtExposure',
                                                                    'BsmtFinType1',
                                                                    'BsmtFinType2',
                                                                    'Heating',
                                                                    'HeatingQC',
                                                                    'Electrical',
                                                                    'KitchenQual',
                                                                    'Functional',
                                                                    'FireplaceQu',
                                                                    'GarageType', ...],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=9999))])
2025-10-28 14:50:20,981:INFO:create_model() successfully completed......................................
2025-10-28 14:50:21,113:INFO:_master_model_container: 21
2025-10-28 14:50:21,113:INFO:_display_container: 5
2025-10-28 14:50:21,153:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Id', 'MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'BsmtFullBath', 'BsmtHalfBath',
                                             'FullBath', 'Hal...
                                                                    'Exterior1st',
                                                                    'Exterior2nd',
                                                                    'MasVnrType',
                                                                    'ExterQual',
                                                                    'ExterCond',
                                                                    'Foundation',
                                                                    'BsmtQual',
                                                                    'BsmtCond',
                                                                    'BsmtExposure',
                                                                    'BsmtFinType1',
                                                                    'BsmtFinType2',
                                                                    'Heating',
                                                                    'HeatingQC',
                                                                    'Electrical',
                                                                    'KitchenQual',
                                                                    'Functional',
                                                                    'FireplaceQu',
                                                                    'GarageType', ...],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=9999))])
2025-10-28 14:50:21,153:INFO:finalize_model() successfully completed......................................
2025-10-28 14:50:26,898:INFO:Initializing save_model()
2025-10-28 14:50:26,898:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Id', 'MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'BsmtFullBath', 'BsmtHalfBath',
                                             'FullBath', 'Hal...
                                                                    'Exterior1st',
                                                                    'Exterior2nd',
                                                                    'MasVnrType',
                                                                    'ExterQual',
                                                                    'ExterCond',
                                                                    'Foundation',
                                                                    'BsmtQual',
                                                                    'BsmtCond',
                                                                    'BsmtExposure',
                                                                    'BsmtFinType1',
                                                                    'BsmtFinType2',
                                                                    'Heating',
                                                                    'HeatingQC',
                                                                    'Electrical',
                                                                    'KitchenQual',
                                                                    'Functional',
                                                                    'FireplaceQu',
                                                                    'GarageType', ...],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=9999))]), model_name=final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\LESANM~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Id', 'MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'B...
                                                                    'Condition2',
                                                                    'BldgType',
                                                                    'HouseStyle',
                                                                    'RoofStyle',
                                                                    'RoofMatl',
                                                                    'Exterior1st',
                                                                    'Exterior2nd',
                                                                    'MasVnrType',
                                                                    'ExterQual',
                                                                    'ExterCond',
                                                                    'Foundation',
                                                                    'BsmtQual',
                                                                    'BsmtCond',
                                                                    'BsmtExposure',
                                                                    'BsmtFinType1',
                                                                    'BsmtFinType2',
                                                                    'Heating',
                                                                    'HeatingQC',
                                                                    'Electrical',
                                                                    'KitchenQual',
                                                                    'Functional',
                                                                    'FireplaceQu',
                                                                    'GarageType', ...],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-10-28 14:50:26,898:INFO:Adding model into prep_pipe
2025-10-28 14:50:26,898:WARNING:Only Model saved as it was a pipeline.
2025-10-28 14:50:26,959:INFO:final_model.pkl saved in current working directory
2025-10-28 14:50:27,015:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Id', 'MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'BsmtFullBath', 'BsmtHalfBath',
                                             'FullBath', 'Hal...
                                                                    'Exterior1st',
                                                                    'Exterior2nd',
                                                                    'MasVnrType',
                                                                    'ExterQual',
                                                                    'ExterCond',
                                                                    'Foundation',
                                                                    'BsmtQual',
                                                                    'BsmtCond',
                                                                    'BsmtExposure',
                                                                    'BsmtFinType1',
                                                                    'BsmtFinType2',
                                                                    'Heating',
                                                                    'HeatingQC',
                                                                    'Electrical',
                                                                    'KitchenQual',
                                                                    'Functional',
                                                                    'FireplaceQu',
                                                                    'GarageType', ...],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=9999))])
2025-10-28 14:50:27,015:INFO:save_model() successfully completed......................................
